{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 765,
          "status": "ok",
          "timestamp": 1744397931823,
          "user": {
            "displayName": "Sebastian Quintero",
            "userId": "09931033526221733334"
          },
          "user_tz": 240
        },
        "id": "F5VeEmlUuZss",
        "outputId": "82cfb451-10ab-405d-f1f6-bedf490940b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/THESIS/rag-thesis\n"
          ]
        }
      ],
      "source": [
        "cd '/content/drive/MyDrive/THESIS/rag-thesis'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 7938,
          "status": "ok",
          "timestamp": 1744397939765,
          "user": {
            "displayName": "Sebastian Quintero",
            "userId": "09931033526221733334"
          },
          "user_tz": 240
        },
        "id": "gLKekmCXumcS",
        "outputId": "5c5da0eb-d359-4b40-850d-f8f8c9172eec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement tdqdm (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tdqdm\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q -U -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "executionInfo": {
          "elapsed": 3317,
          "status": "ok",
          "timestamp": 1744397943083,
          "user": {
            "displayName": "Sebastian Quintero",
            "userId": "09931033526221733334"
          },
          "user_tz": 240
        },
        "id": "qo7mm1Kpv87J"
      },
      "outputs": [],
      "source": [
        "!pip install -q backoff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "executionInfo": {
          "elapsed": 38325,
          "status": "ok",
          "timestamp": 1744397981415,
          "user": {
            "displayName": "Sebastian Quintero",
            "userId": "09931033526221733334"
          },
          "user_tz": 240
        },
        "id": "0qHhDWoauKNM",
        "outputId": "36065efb-d0d7-47b7-ad3d-b7e64bcfb574"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 223,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 221,\n        \"samples\": [\n          \"Trade moves jobs from import-competing industries to export industries.\",\n          \"Suppose that country 1 is capital abundant relative to country 2. Both produce two goods (X\\nand Y). Factor-intensity reversal occurs whenever:\",\n          \"Some goods generate spillover benefits from production, but it is:\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OptionA\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 135,\n        \"samples\": [\n          \"capital is specific to computer production.\",\n          \"increased demand for foreign goods.\",\n          \"equilibrium relative price\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OptionB\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 134,\n        \"samples\": [\n          \"Country B will export good X.\",\n          \"trade restrictions such as tariffs and quotas.\",\n          \"trade triangle\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OptionC\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 133,\n        \"samples\": [\n          \"Excessive job creation can destroy economic growth.\",\n          \"Almost all the children went back to school to learn a more lucrative trade.\",\n          \"II and III only\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OptionD\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 130,\n        \"samples\": [\n          \"Unemployment is a bad thing.\",\n          \"harm domestic consumers.\",\n          \"The optimal tariff argument\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"C\",\n          \"A\",\n          \"B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Feedback\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"The increase in German labor force LG will increase the relative supply\\nof beer. Given the Cogg-Douglas preferences, the relative demand is downward-sloping.\\nThus, the relative price of beer will fall, which is a terms of trade improvement for\\nFrench workers but deterioration for German workers.\",\n          \"Tariffs and quotas are no longer equivalent when firms have market power. In this case, the tariff alleviates the monopoly distortion, whereas the quota does not.\",\n          \"The estimated gravity model suggests that trade is roughly proportional to country\\nsize.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"theory\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"numerical\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"grouping\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fill_in_blank\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"true_false\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_test"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-54768dd8-7896-4fa4-94b4-e675b6079033\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>OptionA</th>\n",
              "      <th>OptionB</th>\n",
              "      <th>OptionC</th>\n",
              "      <th>OptionD</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Feedback</th>\n",
              "      <th>theory</th>\n",
              "      <th>numerical</th>\n",
              "      <th>grouping</th>\n",
              "      <th>fill_in_blank</th>\n",
              "      <th>true_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the reasons protectionists and governme...</td>\n",
              "      <td>quotas generate more revenue for the governmen...</td>\n",
              "      <td>quotas ensure that the quantities of imports a...</td>\n",
              "      <td>quotas create less market distortions than tar...</td>\n",
              "      <td>quotas give less power to politicians than tar...</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In the case of a small country, the effects of...</td>\n",
              "      <td>the government allocates licenses for free to ...</td>\n",
              "      <td>the government auctions off import licenses to...</td>\n",
              "      <td>the government allocates licenses to importers...</td>\n",
              "      <td>the government allocates import licenses direc...</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A small country imports T-shirts. With free tr...</td>\n",
              "      <td>gain $5 million.</td>\n",
              "      <td>lose $5 million.</td>\n",
              "      <td>gain $25 million.</td>\n",
              "      <td>gain $30 million.</td>\n",
              "      <td>C</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A small country imports T-shirts. With free tr...</td>\n",
              "      <td>gain $7 million.</td>\n",
              "      <td>lose $7 million.</td>\n",
              "      <td>lose $70 million.</td>\n",
              "      <td>lose $77 million.</td>\n",
              "      <td>D</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A small country imports T-shirts. With free tr...</td>\n",
              "      <td>$30 million</td>\n",
              "      <td>$40 million</td>\n",
              "      <td>$70 million</td>\n",
              "      <td>$240 million</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>Specific factors are more likely to favor trad...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A</td>\n",
              "      <td>Workers can move away from the sector whose pr...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>Factor prices are more likely to be equalized ...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>B</td>\n",
              "      <td>When countries are not completely specialized,...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>The European Common Agricultural Policy is a b...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>B</td>\n",
              "      <td>The European Common Agricultural Policy entail...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>Immigration necessarily lowers wages.</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>B</td>\n",
              "      <td>For example, when factor price equalization ho...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>Offshoring cannot raise the real wage of the w...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>B</td>\n",
              "      <td>Grossman and Rossi-Hansberg offer a scenario u...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>223 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54768dd8-7896-4fa4-94b4-e675b6079033')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54768dd8-7896-4fa4-94b4-e675b6079033 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54768dd8-7896-4fa4-94b4-e675b6079033');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d69cd603-a55d-4d26-96c0-d42e1340ecb9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d69cd603-a55d-4d26-96c0-d42e1340ecb9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d69cd603-a55d-4d26-96c0-d42e1340ecb9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_62608d50-a14f-441b-bd0b-66d93c41b204\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_62608d50-a14f-441b-bd0b-66d93c41b204 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              Question  \\\n",
              "0    One of the reasons protectionists and governme...   \n",
              "1    In the case of a small country, the effects of...   \n",
              "2    A small country imports T-shirts. With free tr...   \n",
              "3    A small country imports T-shirts. With free tr...   \n",
              "4    A small country imports T-shirts. With free tr...   \n",
              "..                                                 ...   \n",
              "218  Specific factors are more likely to favor trad...   \n",
              "219  Factor prices are more likely to be equalized ...   \n",
              "220  The European Common Agricultural Policy is a b...   \n",
              "221              Immigration necessarily lowers wages.   \n",
              "222  Offshoring cannot raise the real wage of the w...   \n",
              "\n",
              "                                               OptionA  \\\n",
              "0    quotas generate more revenue for the governmen...   \n",
              "1    the government allocates licenses for free to ...   \n",
              "2                                     gain $5 million.   \n",
              "3                                     gain $7 million.   \n",
              "4                                          $30 million   \n",
              "..                                                 ...   \n",
              "218                                               True   \n",
              "219                                               True   \n",
              "220                                               True   \n",
              "221                                               True   \n",
              "222                                               True   \n",
              "\n",
              "                                               OptionB  \\\n",
              "0    quotas ensure that the quantities of imports a...   \n",
              "1    the government auctions off import licenses to...   \n",
              "2                                     lose $5 million.   \n",
              "3                                     lose $7 million.   \n",
              "4                                          $40 million   \n",
              "..                                                 ...   \n",
              "218                                              False   \n",
              "219                                              False   \n",
              "220                                              False   \n",
              "221                                              False   \n",
              "222                                              False   \n",
              "\n",
              "                                               OptionC  \\\n",
              "0    quotas create less market distortions than tar...   \n",
              "1    the government allocates licenses to importers...   \n",
              "2                                    gain $25 million.   \n",
              "3                                    lose $70 million.   \n",
              "4                                          $70 million   \n",
              "..                                                 ...   \n",
              "218                                                NaN   \n",
              "219                                                NaN   \n",
              "220                                                NaN   \n",
              "221                                                NaN   \n",
              "222                                                NaN   \n",
              "\n",
              "                                               OptionD Answer  \\\n",
              "0    quotas give less power to politicians than tar...      B   \n",
              "1    the government allocates import licenses direc...      B   \n",
              "2                                    gain $30 million.      C   \n",
              "3                                    lose $77 million.      D   \n",
              "4                                         $240 million      B   \n",
              "..                                                 ...    ...   \n",
              "218                                                NaN      A   \n",
              "219                                                NaN      B   \n",
              "220                                                NaN      B   \n",
              "221                                                NaN      B   \n",
              "222                                                NaN      B   \n",
              "\n",
              "                                              Feedback  theory  numerical  \\\n",
              "0                                                  NaN       1          0   \n",
              "1                                                  NaN       0          1   \n",
              "2                                                  NaN       0          1   \n",
              "3                                                  NaN       0          1   \n",
              "4                                                  NaN       0          1   \n",
              "..                                                 ...     ...        ...   \n",
              "218  Workers can move away from the sector whose pr...       0          0   \n",
              "219  When countries are not completely specialized,...       0          0   \n",
              "220  The European Common Agricultural Policy entail...       0          0   \n",
              "221  For example, when factor price equalization ho...       0          0   \n",
              "222  Grossman and Rossi-Hansberg offer a scenario u...       0          0   \n",
              "\n",
              "     grouping  fill_in_blank  true_false  \n",
              "0           0              0           0  \n",
              "1           0              0           0  \n",
              "2           0              0           0  \n",
              "3           0              0           0  \n",
              "4           0              0           0  \n",
              "..        ...            ...         ...  \n",
              "218         0              0           1  \n",
              "219         0              0           1  \n",
              "220         0              0           1  \n",
              "221         0              0           1  \n",
              "222         0              0           1  \n",
              "\n",
              "[223 rows x 12 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "#import datasets\n",
        "#from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaTokenizerFast, LlamaForCausalLM, LlamaTokenizer\n",
        "from sklearn.metrics import classification_report\n",
        "from peft import PeftModel\n",
        "import random\n",
        "import time\n",
        "\n",
        "from eval_utils import *\n",
        "\n",
        "df_test = pd.read_excel(\"data/multipleChoice.xlsx\" )\n",
        "# only keep first 50 rows\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 54,
          "status": "ok",
          "timestamp": 1744397989656,
          "user": {
            "displayName": "Sebastian Quintero",
            "userId": "09931033526221733334"
          },
          "user_tz": 240
        },
        "id": "042yXuUyuKNN",
        "outputId": "8b1b8d89-ba9b-49ca-f73f-d8e47af99f77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question Type Distribution:\n",
            "==========================\n",
            "               Count  Percentage (%)\n",
            "theory            36           16.14\n",
            "numerical         11            4.93\n",
            "grouping           5            2.24\n",
            "fill_in_blank     82           36.77\n",
            "true_false        89           39.91\n",
            "\n",
            "Total number of questions: 223\n"
          ]
        }
      ],
      "source": [
        "# Sum up the dummy variables to get counts for each category\n",
        "category_counts = df_test[['theory', 'numerical', 'grouping', 'fill_in_blank', 'true_false']].sum()\n",
        "\n",
        "# Calculate percentages\n",
        "total_questions = len(df_test)\n",
        "category_percentages = (category_counts / total_questions * 100).round(2)\n",
        "\n",
        "# Create a summary DataFrame\n",
        "summary_df = pd.DataFrame({\n",
        "    'Count': category_counts,\n",
        "    'Percentage (%)': category_percentages\n",
        "})\n",
        "\n",
        "print(\"Question Type Distribution:\")\n",
        "print(\"==========================\")\n",
        "print(summary_df)\n",
        "print(f\"\\nTotal number of questions: {total_questions}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3937,
          "status": "ok",
          "timestamp": 1744134562381,
          "user": {
            "displayName": "Sebastian Quintero",
            "userId": "09931033526221733334"
          },
          "user_tz": 240
        },
        "id": "-tDN5VjCeGlE",
        "outputId": "6e3a5292-53be-4b51-e42e-c6e1d2fde9e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diamonds are not something that should be cooked, as they are not food. Diamonds are carbon-based gemstones formed under high pressure and temperature conditions deep within the Earth over millions of years. If exposed to extreme conditions artificially, such as extremely high temperatures, diamonds might burn or degrade in the presence of oxygen. If you have any diamond-related queries or need advice on caring for them or their settings, feel free to ask!\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key=\"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\"\n",
        ")\n",
        "\n",
        "def prompt_gpt4o(prompt):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        store=True,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "print(prompt_gpt4o(\"What is the proper way to cook a diamond?\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "executionInfo": {
          "elapsed": 1,
          "status": "ok",
          "timestamp": 1744398003865,
          "user": {
            "displayName": "Sebastian Quintero",
            "userId": "09931033526221733334"
          },
          "user_tz": 240
        },
        "id": "Y9MyykJui08x"
      },
      "outputs": [],
      "source": [
        "prompt = \"Answer the following multiple choice question with ONLY a single letter (A, B, C, or D). Do not include any other text, punctuation, or explanation - just the letter.\\n\\\n",
        "Question: {}\\n\\\n",
        "A) {}\\n\\\n",
        "B) {}\\n\\\n",
        "C) {}\\n\\\n",
        "D) {}\\n\\\n",
        "Answer:\"\n",
        "\n",
        "prompt_tf = \"Answer the following true/false question. Respond only with the letter A if the statement is true, or B if the statement is false. Do not include any other text, punctuation, or explanation - just the letter.\\n\\\n",
        "Question: {}\\n\\\n",
        "A) {}\\n\\\n",
        "B) {}\\n\\\n",
        "Answer:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "executionInfo": {
          "elapsed": 14,
          "status": "ok",
          "timestamp": 1744398005182,
          "user": {
            "displayName": "Sebastian Quintero",
            "userId": "09931033526221733334"
          },
          "user_tz": 240
        },
        "id": "bTLf0hoOjy_d"
      },
      "outputs": [],
      "source": [
        "cot_prompt = \"\"\"Lets think step by step in the folliwng multiple choice question:\n",
        "\n",
        "Question: The country Rich is relatively well endowed with skilled labor whereas its trade partner, Poor, is relatively well endowed with unskilled labor. The two countries produce and freely trade two goods using the same constant-returns-to-scale technologies. The countries have identical and homothetic preferences. In this setting, when trade opens, what happens?\n",
        "\n",
        "A) The real wage of skilled workers in Rich must rise, the real wage of unskilled\n",
        "workers in Rich must fall, and the income rise for skilled workers need not exceed\n",
        "the income fall for unskilled workers.\n",
        "\n",
        "B) The real wage of unskilled workers in Rich must rise, the real wage of skilled\n",
        "workers in Rich must fall, and the income rise for unskilled workers need not exceed the income fall for skilled workers\n",
        "\n",
        "C) The real wage of unskilled workers in Rich must rise, the real wage of skilled\n",
        "workers in Rich must fall, and the income rise for unskilled workers must exceed the income fall for skilled workers.\n",
        "\n",
        "D) The real wage of skilled workers in Rich must rise, the real wage of unskilled workers in Rich must fall, and the income rise for skilled workers must exceed the income fall for unskilled workers.\n",
        "\n",
        "Answer:\n",
        "1. By the Heckscher-Ohlin Theorem, the relative price of the skill-intensive good must increase in Rich.\n",
        "2. By the Stolper-Samuelson theorem, the real wage for skilled workers in Rich must rise and the real wage for unskilled workers in Rich must fall.\n",
        "3. Since there are aggregate gains from trade, the income rise for skilled workers as a whole must exceed the income fall for unskilled workers as a whole.\n",
        "4. Thus,the answer is option D: \"The real wage of skilled workers in Rich must rise, the real wage of unskilled workers in Rich must fall, and the income rise for skilled workers must exceed the income fall for unskilled workers.\"\n",
        "\n",
        "Now answer the following multiple choice question with ONLY a single letter (A, B, C, or D). Do not include any other text, punctuation, or explanation - just the letter.\n",
        "\n",
        "Question: {}\n",
        "\n",
        "A) {}\n",
        "B) {}\n",
        "C) {}\n",
        "D) {}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "cot_prompt_tf = \"\"\"Lets think step by step in the followng true or false question:\n",
        "\n",
        "Question: Trade between the US and China is more likely to benefit US high-tech workers and hurt US low-tech workers.\n",
        "\n",
        "A) True\n",
        "B) False\n",
        "\n",
        "Answer:\n",
        "1. The US is more abundant in high-tech workers than in low-tech workers relative to China.\n",
        "2. Trade will induce a decline in the wage of the US low-tech workers relative to the wage of the US high-tech workers, as low-tech labor becomes less scarse in the US afterstarting to trade with China.\n",
        "3. Said differently, trade essentially allows a country to convert a good x into another good y; so one can see it as new technology.\n",
        "4. Thus, the answer is A: True.\n",
        "\n",
        "Answer the following true/false question. Respond only with the letter A if the statement is true, or B if the statement is false. Do not include any other text, punctuation, or explanation - just the letter.\n",
        "\n",
        "Question: {}\n",
        "\n",
        "A) {}\n",
        "B) {}\n",
        "Answer:\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1744398008477,
          "user": {
            "displayName": "Sebastian Quintero",
            "userId": "09931033526221733334"
          },
          "user_tz": 240
        },
        "id": "eXUsX7Oej4uK"
      },
      "outputs": [],
      "source": [
        "icl_prompt = \"\"\"Answer each multiple choice question with ONLY a single letter (A, B, C, or D).\n",
        "Here are some examples:\n",
        "\n",
        "Example 1: There are two large countries, the United States and China, and two goods, solar panels and soy bean. The United exports soy beans and imports solar panels. If the United States imposes a small import tariff on solar panels, whereas China imposes a small import tariff on soy beans, then:\n",
        "\n",
        "A) Both countries are better off than under free trade.\n",
        "B) Both countries are worse off than under free trade.\n",
        "C) The United States is better off than under free trade, but China is worse off.\n",
        "D) China is better off than under free trade, but the United States is worse off.\n",
        "\n",
        "Answer: B) Both countries are worse off than under free trade.\n",
        "\n",
        "Example 2: Consider a Ricardian trade model with two goods, Wine and Cheese, and many countries. Suppose France requires less labor to produce Cheese than Italy. Then:\n",
        "\n",
        "A) France might import Cheese from Italy.\n",
        "B) France might import Cheese from the rest of the world, but cannot import from Italy.\n",
        "C) France must export Cheese to country Italy.\n",
        "D) France must export Cheese to the rest of the world, but not necessarily to Italy.\n",
        "\n",
        "Answer: A) France might import Cheese from Italy.\n",
        "\n",
        "Example 3: If a tariff decreases domestic consumption of a good from 230 million units to 150 million units and raises the domestic price by $1.50, given a linear domestic demand curve and a perfectly elastic world supply curve, what is the value of the unexploited gains from trade caused by decreased domestic consumption?\n",
        "\n",
        "A) $45 million\n",
        "B) $60 million\n",
        "C) $80 million\n",
        "D) $120 million\n",
        "\n",
        "Answer: B) $60 million\n",
        "\n",
        "Now answer the following multiple choice question with ONLY a single letter (A, B, C, or D). Do not include any other text, punctuation, or explanation - just the letter.\n",
        "\n",
        "Question: {}\n",
        "\n",
        "A) {}\n",
        "B) {}\n",
        "C) {}\n",
        "D) {}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "icl_prompt_tf = \"\"\"Examine the answers to the following true or false question:\n",
        "\n",
        "Example 1: Offshoring cannot raise the real wage of the workers whose jobs are being offshored.\n",
        "A) True\n",
        "B) False\n",
        "\n",
        "Answer: B) False\n",
        "\n",
        "Example 2: Specific factors are more likely to favor trade protection than mobile factors.\n",
        "A) True\n",
        "B) False\n",
        "\n",
        "Answer: A) True\n",
        "\n",
        "\n",
        "Example 3: Factor prices are more likely to be equalized across countries if countries are completely specialized.\n",
        "A) True\n",
        "B) False\n",
        "\n",
        "Answer: B) False\n",
        "\n",
        "\n",
        "Answer the following true/false question. Respond only with the letter A if the statement is true, or B if the statement is false. Do not include any other text, punctuation, or explanation - just the letter.\n",
        "\n",
        "Question: {}\n",
        "\n",
        "A) {}\n",
        "B) {}\n",
        "Answer:\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "collapsed": true,
        "executionInfo": {
          "elapsed": 112295,
          "status": "ok",
          "timestamp": 1744136717791,
          "user": {
            "displayName": "Sebastian Quintero",
            "userId": "09931033526221733334"
          },
          "user_tz": 240
        },
        "id": "k8YhuU0buKNN",
        "outputId": "82b2a982-625e-4675-b292-59f3b236f273"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 223/223 [01:52<00:00,  1.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Detailed Answer Matching:\n",
            "------------------------\n",
            "Found 30 mismatches out of 223 questions\n",
            "\n",
            "Results for gpt-4o\n",
            "==================================================\n",
            "Overall Accuracy: 0.8655 (193/223 correct)\n",
            "\n",
            "Per-Category Performance:\n",
            "------------------------------\n",
            "Theory:\n",
            "  Accuracy: 0.9444\n",
            "  Correct: 34/36\n",
            "\n",
            "Numerical:\n",
            "  Accuracy: 0.6364\n",
            "  Correct: 7/11\n",
            "\n",
            "Grouping:\n",
            "  Accuracy: 0.8000\n",
            "  Correct: 4/5\n",
            "\n",
            "Fill In Blank:\n",
            "  Accuracy: 0.8415\n",
            "  Correct: 69/82\n",
            "\n",
            "True False:\n",
            "  Accuracy: 0.8876\n",
            "  Correct: 79/89\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n    # Save results to file\\n    with open(\"results/LLM_results.txt\", \"a\") as f:\\n        f.write(f\"\\nResults for {MODEL_NAME}\\n\")\\n        f.write(\"=\" * 50 + \"\\n\")\\n        f.write(f\"Overall Accuracy: {overall_accuracy:.4f} ({correct_answers}/{total_questions} correct)\\n\")\\n        f.write(\"\\nPer-Category Performance:\\n\")\\n        f.write(\"-\" * 30 + \"\\n\")\\n\\n        for category, results in category_results.items():\\n            f.write(f\"{category.replace(\\'_\\', \\' \\').title()}:\\n\")\\n            f.write(f\"  Accuracy: {results[\\'accuracy\\']:.4f}\\n\")\\n            f.write(f\"  Correct: {results[\\'correct\\']}/{results[\\'total\\']}\\n\\n\")\\n        f.write(\"\\n\")\\n        '"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "for MODEL_NAME in [\"gpt-4o\"]:\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    for row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
        "        #time.sleep(1)\n",
        "        question = row[1][\"Question\"]\n",
        "        choice_a = row[1][\"OptionA\"]\n",
        "        choice_b = row[1][\"OptionB\"]\n",
        "        choice_c = row[1][\"OptionC\"]\n",
        "        choice_d = row[1][\"OptionD\"]\n",
        "        label = row[1][\"Answer\"].strip().upper()  # Clean the true label\n",
        "\n",
        "        if MODEL_NAME == \"gpt-4o\":\n",
        "            if row[1][\"true_false\"]:\n",
        "                prediction = prompt_gpt4o_with_backoff(icl_prompt_tf.format(\n",
        "                    question, choice_a, choice_b))\n",
        "            else:\n",
        "                prediction = prompt_gpt4o_with_backoff(icl_prompt.format(\n",
        "                    question, choice_a, choice_b, choice_c, choice_d))\n",
        "\n",
        "        # Clean and extract the predicted answer letter more carefully\n",
        "        pred_letter = prediction.strip().upper()\n",
        "        # If the prediction contains more than just the letter, take first word\n",
        "        if len(pred_letter) > 1:\n",
        "            pred_letter = pred_letter[0]\n",
        "\n",
        "        # Validate prediction format\n",
        "        if pred_letter not in ['A', 'B', 'C', 'D']:\n",
        "            print(f\"Warning: Invalid prediction format: '{prediction}' for question: {question}\")\n",
        "            pred_letter = random.choice(['A', 'B', 'C', 'D'])\n",
        "\n",
        "        y_pred.append(pred_letter)\n",
        "        y_true.append(label)\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        # Print debugging info for all predictions\n",
        "        if pred_letter != label:\n",
        "            print(\"\\nIncorrect Prediction:\")\n",
        "            print(f\"Question: {question}\")\n",
        "            print(f\"Choices:\")\n",
        "            print(f\"A) {choice_a}\")\n",
        "            print(f\"B) {choice_b}\")\n",
        "            if not row[1][\"true_false\"]:\n",
        "                print(f\"C) {choice_c}\")\n",
        "                print(f\"D) {choice_d}\")\n",
        "            print(f\"Raw model response: '{prediction}'\")\n",
        "            print(f\"Processed prediction: '{pred_letter}'\")\n",
        "            print(f\"Correct answer: '{label}'\")\n",
        "            print(\"=========================================================\")\n",
        "        \"\"\"\n",
        "\n",
        "    # Calculate overall accuracy\n",
        "    total_questions = len(y_true)\n",
        "    correct_answers = sum(1 for pred, true in zip(y_pred, y_true) if pred == true)\n",
        "    overall_accuracy = correct_answers / total_questions\n",
        "\n",
        "    # Print detailed matching information\n",
        "    print(\"\\nDetailed Answer Matching:\")\n",
        "    print(\"------------------------\")\n",
        "    mismatches = [(i, pred, true) for i, (pred, true) in enumerate(zip(y_pred, y_true)) if pred != true]\n",
        "    print(f\"Found {len(mismatches)} mismatches out of {total_questions} questions\")\n",
        "\n",
        "    # Calculate per-category accuracies\n",
        "    categories = ['theory', 'numerical', 'grouping', 'fill_in_blank', 'true_false']\n",
        "    category_results = {}\n",
        "\n",
        "    for category in categories:\n",
        "        # Get questions belonging to this category\n",
        "        category_indices = df_test[df_test[category] == 1].index\n",
        "\n",
        "        if len(category_indices) > 0:\n",
        "            category_correct = sum(1 for i in category_indices if y_pred[i] == y_true[i])\n",
        "            category_accuracy = category_correct / len(category_indices)\n",
        "            category_results[category] = {\n",
        "                'accuracy': category_accuracy,\n",
        "                'correct': category_correct,\n",
        "                'total': len(category_indices)\n",
        "            }\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\nResults for {MODEL_NAME}\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Overall Accuracy: {overall_accuracy:.4f} ({correct_answers}/{total_questions} correct)\")\n",
        "    print(\"\\nPer-Category Performance:\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    for category, results in category_results.items():\n",
        "        print(f\"{category.replace('_', ' ').title()}:\")\n",
        "        print(f\"  Accuracy: {results['accuracy']:.4f}\")\n",
        "        print(f\"  Correct: {results['correct']}/{results['total']}\")\n",
        "        print()\n",
        "\"\"\"\n",
        "    # Save results to file\n",
        "    with open(\"results/LLM_results.txt\", \"a\") as f:\n",
        "        f.write(f\"\\nResults for {MODEL_NAME}\\n\")\n",
        "        f.write(\"=\" * 50 + \"\\n\")\n",
        "        f.write(f\"Overall Accuracy: {overall_accuracy:.4f} ({correct_answers}/{total_questions} correct)\\n\")\n",
        "        f.write(\"\\nPer-Category Performance:\\n\")\n",
        "        f.write(\"-\" * 30 + \"\\n\")\n",
        "\n",
        "        for category, results in category_results.items():\n",
        "            f.write(f\"{category.replace('_', ' ').title()}:\\n\")\n",
        "            f.write(f\"  Accuracy: {results['accuracy']:.4f}\\n\")\n",
        "            f.write(f\"  Correct: {results['correct']}/{results['total']}\\n\\n\")\n",
        "        f.write(\"\\n\")\n",
        "        \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3050,
          "status": "ok",
          "timestamp": 1743799983415,
          "user": {
            "displayName": "Sebastian Quintero",
            "userId": "09931033526221733334"
          },
          "user_tz": 240
        },
        "id": "Qv3AVRBv0xE-",
        "outputId": "a95ff1dc-b1c3-4c29-e570-c9e2ce9ded0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zY8TIHD600cT"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login(token=\"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\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "executionInfo": {
          "elapsed": 130628,
          "status": "ok",
          "timestamp": 1743800117096,
          "user": {
            "displayName": "Sebastian Quintero",
            "userId": "09931033526221733334"
          },
          "user_tz": 240
        },
        "id": "pkFfBEOKgE_b",
        "outputId": "77f3a9ea-18dd-4d5b-c171-b12e427f85dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl (76.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.45.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "ef6b6da69e6440bdbe273aad1ba01390",
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -q -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTaBeHNbfP7V"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate huggingface_hub bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjApblsKuO4Y"
      },
      "outputs": [],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475,
          "referenced_widgets": [
            "ae52f2ff665e46a9a454ca2d69456b45",
            "796ddb262a744a75a2a403edd11bf420",
            "cd35fb35c4a547629c45f885b38548c0",
            "dcf07be293af4622b8a97d65ab183d47",
            "a0a497b9437748a2b7f28ee37fc245b0",
            "65c80c67e5114af4898543cb028a9f2f",
            "b25b80b342a84e69ad8b3c0a0692761b",
            "f292ae731c7548af8bcdf0935a682b28",
            "5f75e94cb08f480382cb6c18ecc66ef8",
            "4d4e9260aac84b04a4104f93267214be",
            "a7d3856191ca486b97e78d7b1a96aa23"
          ]
        },
        "executionInfo": {
          "elapsed": 1636,
          "status": "error",
          "timestamp": 1743800737004,
          "user": {
            "displayName": "Sebastian Quintero",
            "userId": "09931033526221733334"
          },
          "user_tz": 240
        },
        "id": "8lfGyRkwuKNO",
        "outputId": "f810e4e5-5b04-4f72-a230-55d5f2a7bf20"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae52f2ff665e46a9a454ca2d69456b45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 128.12 MiB is free. Process 44972 has 14.61 GiB memory in use. Of the allocated memory 14.46 GiB is allocated by PyTorch, and 53.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3b9cc12c871a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    574\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4453\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4454\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4455\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4456\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4457\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, low_cpu_mem_usage, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, device_mesh, key_mapping, weights_only, _fast_init)\u001b[0m\n\u001b[1;32m   4882\u001b[0m                 \u001b[0;31m# Skip it with fsdp on ranks other than 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4883\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_fsdp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_local_dist_rank_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_quantized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4884\u001b[0;31m                     disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n\u001b[0m\u001b[1;32m   4885\u001b[0m                         \u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4886\u001b[0m                         \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys, device_mesh)\u001b[0m\n\u001b[1;32m    812\u001b[0m             )\n\u001b[1;32m    813\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcasting_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                 \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasting_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 128.12 MiB is free. Process 44972 has 14.61 GiB memory in use. Of the allocated memory 14.46 GiB is allocated by PyTorch, and 53.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "def get_zero_shot_results_from_llama(df_test, model, tokenizer):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
        "        question = row[1][\"Question\"]\n",
        "        choice_a = row[1][\"OptionA\"]\n",
        "        choice_b = row[1][\"OptionB\"]\n",
        "        choice_c = row[1][\"OptionC\"]\n",
        "        choice_d = row[1][\"OptionD\"]\n",
        "        label = row[1][\"Answer\"]  # Assuming label is 'A', 'B', 'C', or 'D'\n",
        "\n",
        "        prompt = f\"\"\"Please answer this multiple choice question. Only respond with the letter of your answer (A, B, C, or D).\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "A) {choice_a}\n",
        "B) {choice_b}\n",
        "C) {choice_c}\n",
        "D) {choice_d}\n",
        "\n",
        "Answer: \"\"\"\n",
        "\n",
        "        model_answer = prompt_llama_like_model(prompt, model, tokenizer, max_new_tokens=10)\n",
        "        # Extract just the letter answer from the model's response\n",
        "        model_answer = model_answer.split(\"Answer:\")[-1].strip().upper()\n",
        "\n",
        "        # For debugging first few examples\n",
        "        if row[0] < 5:\n",
        "            print(f\"Question: {question}\")\n",
        "            print(f\"Model Answer: {model_answer}\")\n",
        "            print(f\"Correct Answer: {label}\")\n",
        "            print(\"-------------------\")\n",
        "\n",
        "        # Convert letter answers to predictions\n",
        "        y_pred.append(model_answer)\n",
        "        y_true.append(label)\n",
        "\n",
        "    return y_true, y_pred\n",
        "\n",
        "# Remove comments on your desired model\n",
        "\n",
        "\n",
        "# LLAMA2-7B-chat\n",
        "\n",
        "model_id = \"meta-llama/Llama-2-13b-hf\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=True)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"cuda:0\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_auth_token=True\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "y_true, y_pred = get_zero_shot_results_from_llama(df_test.iloc[:5], model, tokenizer)\n",
        "print(classification_report(y_true=y_true,y_pred=y_pred,digits=4))\n",
        "\"\"\"\n",
        "with open(\"results/LLM_results.txt\",\"a\") as f:\n",
        "    f.write(model_name+\", Zero-shot \\n\")\n",
        "    f.write(classification_report(y_true=y_true,y_pred=y_pred,digits=4))\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evQtVdoDKOs3"
      },
      "source": [
        "### Gemini\n",
        "https://aistudio.google.com/apikey"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "executionInfo": {
          "elapsed": 542,
          "status": "ok",
          "timestamp": 1744398020639,
          "user": {
            "displayName": "Sebastian Quintero",
            "userId": "09931033526221733334"
          },
          "user_tz": 240
        },
        "id": "Gzy42lLJsOis"
      },
      "outputs": [],
      "source": [
        "gemini_api_key = 'AIzaSyBvJlgNhUCYhJYHAGEUJeffG0QP8EbjqgQ'\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=\"AIzaSyBvJlgNhUCYhJYHAGEUJeffG0QP8EbjqgQ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1533,
          "status": "ok",
          "timestamp": 1743807541650,
          "user": {
            "displayName": "Sebastian Quintero",
            "userId": "09931033526221733334"
          },
          "user_tz": 240
        },
        "id": "wyDrcCJwsvhl",
        "outputId": "86a9f059-76ee-4d49-9ba6-fd084b9dfe66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=\"\"\"Now answer the following multiple choice question with ONLY a single letter (A, B, C, or D). Do not include any other text, punctuation, or explanation - just the letter.\n",
        "            Question 1: There are two large countries, the United States and China, and two goods, solar panels and soy bean. The United exports soy beans and imports solar panels. If the United States imposes a small import tariff on solar panels, whereas China imposes a small import tariff on soy beans, then:\n",
        "\n",
        "            A) Both countries are better off than under free trade.\n",
        "            B) Both countries are worse off than under free trade.\n",
        "            C) The United States is better off than under free trade, but China is worse off.\n",
        "            D) China is better off than under free trade, but the United States is worse off.\n",
        "\"\"\",\n",
        ")\n",
        "\n",
        "print(type(response.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1419878,
          "status": "ok",
          "timestamp": 1743810308265,
          "user": {
            "displayName": "Sebastian Quintero",
            "userId": "09931033526221733334"
          },
          "user_tz": 240
        },
        "id": "RetYsU999ksV",
        "outputId": "565eb536-aec9-440f-c14b-99fe0f8f0e9d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▏         | 3/223 [00:19<23:44,  6.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: A small country imports T-shirts. With free trade at a world price of $10, domestic production is 10 million T-shirts and domestic consumption is 42 million T-shirts. The country's government now decides to impose a quota to limit T-shirt imports to 20 million per year. With the import quota in place, the domestic price rises to $12 per T-shirt and domestic production rises to 15 million T-shirts per year. The quota on T-shirts causes domestic producers to:\n",
            "Choices:\n",
            "A) gain $5 million.\n",
            "B) lose $5 million.\n",
            "C) gain $25 million.\n",
            "D) gain $30 million.\n",
            "Raw model response: 'D\n",
            "'\n",
            "Processed prediction: 'D'\n",
            "Correct answer: 'C'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 6/223 [00:39<23:36,  6.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: A small country imports T-shirts. With free trade at a world price of $10, domestic production is 10 million T-shirts and domestic consumption is 42 million T-shirts. The country's government now decides to impose a quota to limit T-shirt imports to 20 million per year. With the import quota in place, the domestic price rises to $12 per T-shirt and domestic production rises to 15 million T-shirts per year. If the government auctions the import licenses, the national well-being will ________ by:\n",
            "Choices:\n",
            "A) increase; $40 million.\n",
            "B) decrease; $12 million.\n",
            "C) increase; $65 million.\n",
            "D) decrease; $5 million.\n",
            "Raw model response: 'D\n",
            "'\n",
            "Processed prediction: 'D'\n",
            "Correct answer: 'B'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 28/223 [03:00<20:51,  6.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question:  If the government's goal is to induce early production, even when the new firms are not cost competitive by world standards, a barrier to the import of the product produced by these firms would be an ideal policy.\n",
            "Choices:\n",
            "A) True\n",
            "B) False\n",
            "Raw model response: 'A\n",
            "'\n",
            "Processed prediction: 'A'\n",
            "Correct answer: 'B'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 46/223 [04:56<19:14,  6.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: Which, if any, of the following conditions for efficient market functioning do tariffs and\n",
            "quotas violate?\n",
            "I. demanders with the highest willingness to pay purchase the supply of goods\n",
            "II. producers with the lowest costs produce and sell the supply of goods\n",
            "III. the sum of consumer and producer surplus is maximized\n",
            "Choices:\n",
            "A) I only\n",
            "B) II and III only\n",
            "C) I, II, and III\n",
            "D) III only\n",
            "Raw model response: 'D\n",
            "'\n",
            "Processed prediction: 'D'\n",
            "Correct answer: 'B'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 51/223 [05:28<18:22,  6.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: Suppose that a tariff increases domestic production of a good from 25 million units to 75 million units and raises the domestic price by $1.50. Assuming a linear domestic supply curve and a perfectly elastic world supply curve, what is the value of the resources wasted by increased domestic production?\n",
            "Choices:\n",
            "A) $37.5 million\n",
            "B) $50 million\n",
            "C) $75 million\n",
            "D) $150 million\n",
            "Raw model response: 'B\n",
            "'\n",
            "Processed prediction: 'B'\n",
            "Correct answer: 'A'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 89/223 [09:32<14:12,  6.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: Consider the following two statements and select the best answer.\n",
            "I. The national security argument might be a valid argument for trade protection.\n",
            "II. Industries with spillover effects should be protected from foreign competition.\n",
            "Choices:\n",
            "A) I and II are both true.\n",
            "B) I and II are both false.\n",
            "C) I is likely to be true, and II is likely to be false.\n",
            "D) I is likely to be false, and II is likely to be true.\n",
            "Raw model response: 'A\n",
            "'\n",
            "Processed prediction: 'A'\n",
            "Correct answer: 'C'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████▏     | 92/223 [09:52<14:00,  6.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: The flu pandemic of 1918 provides an example of:\n",
            "Choices:\n",
            "A) a situation for which it makes sense to protect a domestic industry from\n",
            "international competition.\n",
            "B) how trade restrictions lead to deaths and suffering.\n",
            "C) how child labor affects trade flows between countries.\n",
            "D) strategic trade protectionism.\n",
            "Raw model response: 'B\n",
            "'\n",
            "Processed prediction: 'B'\n",
            "Correct answer: 'A'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 99/223 [10:36<13:19,  6.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: Governments can use tariffs to help domestic firms act like a cartel when selling to\n",
            "international buyers:\n",
            "Choices:\n",
            "A) if it's unlikely that other governments would impose retaliatory tariffs.\n",
            "B) and if all governments do this, greater gains are realized by all countries.\n",
            "C) only if international buyers have few substitutes for the domestic good.\n",
            "D) but there are no actual examples of governments trying to do this.\n",
            "Raw model response: 'A\n",
            "'\n",
            "Processed prediction: 'A'\n",
            "Correct answer: 'C'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 101/223 [10:48<12:43,  6.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: If the U.S. government wanted to use strategic trade protectionism for U.S.-produced fertilizer it would:\n",
            "Choices:\n",
            "A) place high taxes on foreign-made fertilizer.\n",
            "B) place a trade quota on foreign-made fertilizer.\n",
            "C) subsidize U.S. producers of fertilizer.\n",
            "D) place a tax or put a limit on the exports of U.S. fertilizer.\n",
            "Raw model response: 'A\n",
            "'\n",
            "Processed prediction: 'A'\n",
            "Correct answer: 'D'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 102/223 [10:54<12:10,  6.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: For strategic trade protectionism to be effective, the:\n",
            "Choices:\n",
            "A) good in question must be produced with high-tech equipment.\n",
            "B) supply of the good in question must be elastic.\n",
            "C) supply of the good in question must be inelastic.\n",
            "D) good in question must be one of many goods that the country exports.\n",
            "Raw model response: 'A\n",
            "'\n",
            "Processed prediction: 'A'\n",
            "Correct answer: 'C'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 103/223 [11:00<12:19,  6.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: The economics of international trade is substantially different from that of ordinary\n",
            "trade.\n",
            "Choices:\n",
            "A) True\n",
            "B) False\n",
            "Raw model response: 'A\n",
            "'\n",
            "Processed prediction: 'A'\n",
            "Correct answer: 'B'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|████▉     | 111/223 [11:50<11:31,  6.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: With free trade, the domestic price of a good must be equal to the world price of a good.\n",
            "Choices:\n",
            "A) True\n",
            "B) False\n",
            "Raw model response: 'B\n",
            "'\n",
            "Processed prediction: 'B'\n",
            "Correct answer: 'A'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 118/223 [12:35<11:15,  6.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: The tariff diagram illustrates that if the absolute value of the slopes of the demand and supply curves are equal, then the deadweight loss of any tariff always equals the wasted resources due to increased domestic production.\n",
            "Choices:\n",
            "A) True\n",
            "B) False\n",
            "Raw model response: 'B\n",
            "'\n",
            "Processed prediction: 'B'\n",
            "Correct answer: 'A'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 132/223 [14:05<09:39,  6.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: We pay for our exports with our imports.\n",
            "Choices:\n",
            "A) True\n",
            "B) False\n",
            "Raw model response: 'A\n",
            "'\n",
            "Processed prediction: 'A'\n",
            "Correct answer: 'B'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 143/223 [15:16<08:34,  6.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: Which statement below is correct?\n",
            "Choices:\n",
            "A) The HO model assumes that all resources can freely move between industries.\n",
            "B) The specific-factors model assumes that all resources can freely move between industries.\n",
            "C) Both the HO and the specific-factor models assume that all resources can freely move between industries.\n",
            "D) Neither the HO nor the specific-factor model assumes that all resources can freely move between industries.\n",
            "Raw model response: 'D\n",
            "'\n",
            "Processed prediction: 'D'\n",
            "Correct answer: 'A'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 145/223 [15:29<08:23,  6.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: In a capital-intensive industry, the capital/labor ratio will:\n",
            "Choices:\n",
            "A) rise as the wage/rental ratio falls.\n",
            "B) fall as the wage/rental ratio falls.\n",
            "C) rise as the country's capital stock rises.\n",
            "D) fall as the country's capital stock falls.\n",
            "Raw model response: 'A\n",
            "'\n",
            "Processed prediction: 'A'\n",
            "Correct answer: 'B'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 147/223 [15:42<08:11,  6.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: Suppose that there are two countries, Home and Foreign, each of which produces two goods, computers and shoes, using two factors of production, labor and capital. Which of the following is not an assumption of the Heckscher-Ohlin model for this situation?\n",
            "Choices:\n",
            "A) Both factors can move freely between sectors.\n",
            "B)  Foreign is capital abundant and Home is labor abundant.\n",
            "C) There is free trade between the countries.\n",
            "D) Shoe production is labor intensive.\n",
            "Raw model response: 'C\n",
            "'\n",
            "Processed prediction: 'C'\n",
            "Correct answer: 'B'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▊   | 153/223 [16:19<07:25,  6.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: Consider two products, automobiles and shoes. If shoes are labor intensive and automobiles are capital intensive, what can we expect in free-trade conditions?\n",
            "Choices:\n",
            "A) The relative price of automobiles in the auto-exporting country will decrease.\n",
            "B) The relative price of shoes in the shoe-exporting country will increase.\n",
            "C) More shoes will be produced by the capital-abundant country.\n",
            "D) More automobiles will be produced by the labor-abundant country.\n",
            "Raw model response: 'A\n",
            "'\n",
            "Processed prediction: 'A'\n",
            "Correct answer: 'B'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 157/223 [16:45<07:08,  6.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: If there are only two nations, one nation's exports are the other's imports; which of the following is identical for both nations?\n",
            "Choices:\n",
            "A) equilibrium relative price\n",
            "B) trade triangle\n",
            "C) opportunity cost\n",
            "D) equilibrium relative price, trade triangle, and opportunity cost\n",
            "Raw model response: 'A\n",
            "'\n",
            "Processed prediction: 'A'\n",
            "Correct answer: 'D'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████▏  | 159/223 [16:58<06:55,  6.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: Suppose Portugal has 700 workers and 26,000 units of capital, and France has 18,000 workers and 700 units of capital. Technology is identical in both countries. Assume that wine is the capital-intensive good and cloth is the laborintensive good. Which of the following statements is correct?\n",
            "Choices:\n",
            "A) Portugal will export wine and import cloth.\n",
            "B) France will export wine and import cloth.\n",
            "C) There is no basis for trade between France and Portugal.\n",
            "D) Portugal will export cloth and import wine.\n",
            "Raw model response: 'D\n",
            "'\n",
            "Processed prediction: 'D'\n",
            "Correct answer: 'A'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 162/223 [17:17<06:35,  6.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: Compared with other countries, the United States' effective factor endowment is greatest for:\n",
            "Choices:\n",
            "A) capital\n",
            "B) R&D scientists.\n",
            "C) arable land.\n",
            "D) unskilled labor.\n",
            "Raw model response: 'A\n",
            "'\n",
            "Processed prediction: 'A'\n",
            "Correct answer: 'B'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 163/223 [17:24<06:29,  6.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: If Japanese workers receive lower wages in the production of autos compared with American workers, then:\n",
            "Choices:\n",
            "A) Japan must have a comparative advantage in the production of autos.\n",
            "B) Japan must have an absolute advantage in the production of autos.\n",
            "C)  auto production costs must be lower in Japan than in the United States.\n",
            "D) auto production costs could be lower in the United States if U.S. labor productivity is higher than Japanese labor productivity.\n",
            "Raw model response: 'C\n",
            "'\n",
            "Processed prediction: 'C'\n",
            "Correct answer: 'D'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▎  | 164/223 [17:30<06:22,  6.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: In a capital-abundant country, free trade will cause a(n) __________ in the rental of capital and a(n) ____________ in the marginal product of capital.\n",
            "Choices:\n",
            "A)  increase; increase\n",
            "B)  increase; decrease\n",
            "C) decrease; decrease\n",
            "D) decrease; increase\n",
            "Raw model response: 'B\n",
            "'\n",
            "Processed prediction: 'B'\n",
            "Correct answer: 'A'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 165/223 [17:37<06:14,  6.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: In a labor-abundant country, free trade will cause a(n) __________ in the rental of capital and a(n) _________ in the marginal product of capital.\n",
            "Choices:\n",
            "A) increase; increase\n",
            "B) increase; decrease\n",
            "C) decrease; decrease\n",
            "D) decrease; increase\n",
            "Raw model response: 'B\n",
            "'\n",
            "Processed prediction: 'B'\n",
            "Correct answer: 'C'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 185/223 [19:42<04:04,  6.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: If a tariff is placed on clocks, the price of both domestic and imported clocks will rise by the amount of the tariff.\n",
            "Choices:\n",
            "A) True\n",
            "B) False\n",
            "Raw model response: 'B\n",
            "'\n",
            "Processed prediction: 'B'\n",
            "Correct answer: 'A'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 202/223 [21:29<02:14,  6.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: A country with higher demand for high-tech goods is more likely to have a comparative advantage in high-tech sectors.\n",
            "Choices:\n",
            "A) True\n",
            "B) False\n",
            "Raw model response: 'A\n",
            "'\n",
            "Processed prediction: 'A'\n",
            "Correct answer: 'B'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 91%|█████████ | 203/223 [21:36<02:08,  6.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: Growth is more likely to increase welfare if it is export-biased.\n",
            "Choices:\n",
            "A) True\n",
            "B) False\n",
            "Raw model response: 'A\n",
            "'\n",
            "Processed prediction: 'A'\n",
            "Correct answer: 'B'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 91%|█████████▏| 204/223 [21:42<02:02,  6.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: According to the Ricardian model, real income is only a function of relative produc-\n",
            "tivity across sectors.\n",
            "Choices:\n",
            "A) True\n",
            "B) False\n",
            "Raw model response: 'A\n",
            "'\n",
            "Processed prediction: 'A'\n",
            "Correct answer: 'B'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 205/223 [21:49<01:55,  6.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: There are two goods, Toys and Cars, and two countries, Japan and China. People have identical homothetic preferences in both countries. Japan has an absolute advantage in producing both goods relative to China, but it has a comparative advantage in producing Cars. Then:\n",
            "Choices:\n",
            "A) The autarky relative price of Cars must be lower in Japan than in China.\n",
            "B) The autarky relative price of Cars must be higher in Japan than in China.\n",
            "C) The autarky relative price of Cars may be higher or lower in Japan than in China.\n",
            "D) The autarky relative prices of both goods will be lower in Japan than in China.\n",
            "Raw model response: 'B\n",
            "'\n",
            "Processed prediction: 'B'\n",
            "Correct answer: 'A'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 207/223 [22:01<01:38,  6.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: Two countries, Big and Small, with identical homothetic preferences, produce two goods, Aircrafts and Computers, using only labor, with constant returns to scale. Big has a labor supply of 200, whereas Small has a labor supply of 30. In Big, the available technology requires 10 units of labor to produce one Aircraft and 4 units of labor to produce one Computer. In Small, the unit labor requirements for Aircraft and Computer are 3 and 1, respectively. Then:\n",
            "Choices:\n",
            "A) Only workers in Big are strictly better oﬀ with free trade than in autarky.\n",
            "B) Only workers in Small are strictly better oﬀ with free trade than in autarky.\n",
            "C) Workers in both countries are strictly better oﬀ with free trade than in autarky.\n",
            "D) We need more information to determine which workers are strictly better oﬀ.\n",
            "Raw model response: 'B\n",
            "'\n",
            "Processed prediction: 'B'\n",
            "Correct answer: 'D'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 212/223 [22:33<01:10,  6.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: The country Rich is relatively well endowed with skilled labor whereas its trade partner, Poor, is relatively well endowed with unskilled labor. The two countries produce and freely trade two goods using the same constant-returns-to-scale technolo-\n",
            "gies. The countries have identical and homothetic preferences. In this setting, when trade opens:\n",
            "Choices:\n",
            "A) The real wage of skilled workers in Rich must rise, the real wage of unskilled\n",
            "workers in Rich must fall, and the income rise for skilled workers need not exceed\n",
            "the income fall for unskilled workers.\n",
            "B) The real wage of unskilled workers in Rich must rise, the real wage of skilled\n",
            "workers in Rich must fall, and the income rise for unskilled workers need not exceed the income fall for skilled workers\n",
            "C) The real wage of unskilled workers in Rich must rise, the real wage of skilled\n",
            "workers in Rich must fall, and the income rise for unskilled workers must exceed the income fall for skilled workers.\n",
            "D) The real wage of skilled workers in Rich must rise, the real wage of unskilled workers in Rich must fall, and the income rise for skilled workers must exceed the income fall for unskilled workers.\n",
            "Raw model response: 'A\n",
            "'\n",
            "Processed prediction: 'A'\n",
            "Correct answer: 'D'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 213/223 [22:39<01:01,  6.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: A country is more likely to benefit if\n",
            "Choices:\n",
            "A) It is large and taxes imports.\n",
            "B) It is small and subsidizes exports.\n",
            "C) It is large and subsidizes exports.\n",
            "D) It is small and taxes imports.\n",
            "Raw model response: 'D\n",
            "'\n",
            "Processed prediction: 'D'\n",
            "Correct answer: 'A'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 214/223 [22:45<00:56,  6.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: A country imports chocolate. Imposing an import tariff on chocolate is more likely to be better than imposing an import quota if:\n",
            "Choices:\n",
            "A) The country is large.\n",
            "B) The country is auctioning export licenses to foreigners.\n",
            "C) The country has a single producer of chocolate.\n",
            "D) None of the above.\n",
            "Raw model response: 'B\n",
            "'\n",
            "Processed prediction: 'B'\n",
            "Correct answer: 'C'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 218/223 [23:09<00:30,  6.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Incorrect Prediction:\n",
            "Question: In a Ricardian model, workers employed in import-competing sectors are more likely to oppose trade.\n",
            "Choices:\n",
            "A) True\n",
            "B) False\n",
            "Raw model response: 'A\n",
            "'\n",
            "Processed prediction: 'A'\n",
            "Correct answer: 'B'\n",
            "=========================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 223/223 [23:39<00:00,  6.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Detailed Answer Matching:\n",
            "------------------------\n",
            "Found 34 mismatches out of 223 questions\n",
            "\n",
            "Results for gemini-2.0-flash\n",
            "==================================================\n",
            "Overall Accuracy: 0.8475 (189/223 correct)\n",
            "\n",
            "Per-Category Performance:\n",
            "------------------------------\n",
            "Theory:\n",
            "  Accuracy: 0.8889\n",
            "  Correct: 32/36\n",
            "\n",
            "Numerical:\n",
            "  Accuracy: 0.6364\n",
            "  Correct: 7/11\n",
            "\n",
            "Grouping:\n",
            "  Accuracy: 0.6000\n",
            "  Correct: 3/5\n",
            "\n",
            "Fill In Blank:\n",
            "  Accuracy: 0.8293\n",
            "  Correct: 68/82\n",
            "\n",
            "True False:\n",
            "  Accuracy: 0.8876\n",
            "  Correct: 79/89\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import time\n",
        "for MODEL_NAME in [\"gemini-2.0-flash\"]:\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    for row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
        "        time.sleep(0.3)\n",
        "        question = row[1][\"Question\"]\n",
        "        choice_a = row[1][\"OptionA\"]\n",
        "        choice_b = row[1][\"OptionB\"]\n",
        "        choice_c = row[1][\"OptionC\"]\n",
        "        choice_d = row[1][\"OptionD\"]\n",
        "        label = row[1][\"Answer\"].strip().upper()  # Clean the true label\n",
        "\n",
        "        # Apply backoff decorator directly to the code block\n",
        "        @backoff.on_exception(backoff.expo, genai.errors.ServerError, max_tries=3)\n",
        "        def _make_api_call():\n",
        "            if row[1][\"true_false\"]:\n",
        "                return client.models.generate_content(\n",
        "                    model=MODEL_NAME,\n",
        "                    contents=prompt_tf.format(question, choice_a, choice_b)\n",
        "                ).text\n",
        "            else:\n",
        "                return client.models.generate_content(\n",
        "                    model=MODEL_NAME,\n",
        "                    contents=prompt.format(question, choice_a, choice_b, choice_c, choice_d)\n",
        "                ).text\n",
        "\n",
        "        prediction = _make_api_call()\n",
        "\n",
        "        # Clean and extract the predicted answer letter more carefully\n",
        "        pred_letter = prediction.strip().upper()\n",
        "        # If the prediction contains more than just the letter, take first word\n",
        "        if len(pred_letter) > 1:\n",
        "            pred_letter = pred_letter[0]\n",
        "\n",
        "        # Validate prediction format\n",
        "        if pred_letter not in ['A', 'B', 'C', 'D']:\n",
        "            print(f\"Warning: Invalid prediction format: '{prediction}' for question: {question}\")\n",
        "            pred_letter = random.choice(['A', 'B', 'C', 'D'])\n",
        "\n",
        "        y_pred.append(pred_letter)\n",
        "        y_true.append(label)\n",
        "\n",
        "        # Print debugging info for all predictions\n",
        "        if pred_letter != label:\n",
        "            print(\"\\nIncorrect Prediction:\")\n",
        "            print(f\"Question: {question}\")\n",
        "            print(f\"Choices:\")\n",
        "            print(f\"A) {choice_a}\")\n",
        "            print(f\"B) {choice_b}\")\n",
        "            if not row[1][\"true_false\"]:\n",
        "                print(f\"C) {choice_c}\")\n",
        "                print(f\"D) {choice_d}\")\n",
        "            print(f\"Raw model response: '{prediction}'\")\n",
        "            print(f\"Processed prediction: '{pred_letter}'\")\n",
        "            print(f\"Correct answer: '{label}'\")\n",
        "            print(\"=========================================================\")\n",
        "\n",
        "    # Calculate overall accuracy\n",
        "    total_questions = len(y_true)\n",
        "    correct_answers = sum(1 for pred, true in zip(y_pred, y_true) if pred == true)\n",
        "    overall_accuracy = correct_answers / total_questions\n",
        "\n",
        "    # Print detailed matching information\n",
        "    print(\"\\nDetailed Answer Matching:\")\n",
        "    print(\"------------------------\")\n",
        "    mismatches = [(i, pred, true) for i, (pred, true) in enumerate(zip(y_pred, y_true)) if pred != true]\n",
        "    print(f\"Found {len(mismatches)} mismatches out of {total_questions} questions\")\n",
        "\n",
        "    # Calculate per-category accuracies\n",
        "    categories = ['theory', 'numerical', 'grouping', 'fill_in_blank', 'true_false']\n",
        "    category_results = {}\n",
        "\n",
        "    for category in categories:\n",
        "        # Get questions belonging to this category\n",
        "        category_indices = df_test[df_test[category] == 1].index\n",
        "\n",
        "        if len(category_indices) > 0:\n",
        "            category_correct = sum(1 for i in category_indices if y_pred[i] == y_true[i])\n",
        "            category_accuracy = category_correct / len(category_indices)\n",
        "            category_results[category] = {\n",
        "                'accuracy': category_accuracy,\n",
        "                'correct': category_correct,\n",
        "                'total': len(category_indices)\n",
        "            }\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\nResults for {MODEL_NAME}\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Overall Accuracy: {overall_accuracy:.4f} ({correct_answers}/{total_questions} correct)\")\n",
        "    print(\"\\nPer-Category Performance:\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    for category, results in category_results.items():\n",
        "        print(f\"{category.replace('_', ' ').title()}:\")\n",
        "        print(f\"  Accuracy: {results['accuracy']:.4f}\")\n",
        "        print(f\"  Correct: {results['correct']}/{results['total']}\")\n",
        "        print()\n",
        "\n",
        "    \"\"\"\n",
        "    # Save results to file\n",
        "    with open(\"results/LLM_results.txt\", \"a\") as f:\n",
        "        f.write(f\"\\nResults for {MODEL_NAME}: Zero-Shot \\n\")\n",
        "        f.write(\"=\" * 50 + \"\\n\")\n",
        "        f.write(f\"Overall Accuracy: {overall_accuracy:.4f} ({correct_answers}/{total_questions} correct)\\n\")\n",
        "        f.write(\"\\nPer-Category Performance:\\n\")\n",
        "        f.write(\"-\" * 30 + \"\\n\")\n",
        "\n",
        "        for category, results in category_results.items():\n",
        "            f.write(f\"{category.replace('_', ' ').title()}:\\n\")\n",
        "            f.write(f\"  Accuracy: {results['accuracy']:.4f}\\n\")\n",
        "            f.write(f\"  Correct: {results['correct']}/{results['total']}\\n\\n\")\n",
        "        f.write(\"\\n\")\n",
        "        \"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d4e9260aac84b04a4104f93267214be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f75e94cb08f480382cb6c18ecc66ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65c80c67e5114af4898543cb028a9f2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "796ddb262a744a75a2a403edd11bf420": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65c80c67e5114af4898543cb028a9f2f",
            "placeholder": "​",
            "style": "IPY_MODEL_b25b80b342a84e69ad8b3c0a0692761b",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "a0a497b9437748a2b7f28ee37fc245b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7d3856191ca486b97e78d7b1a96aa23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae52f2ff665e46a9a454ca2d69456b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_796ddb262a744a75a2a403edd11bf420",
              "IPY_MODEL_cd35fb35c4a547629c45f885b38548c0",
              "IPY_MODEL_dcf07be293af4622b8a97d65ab183d47"
            ],
            "layout": "IPY_MODEL_a0a497b9437748a2b7f28ee37fc245b0"
          }
        },
        "b25b80b342a84e69ad8b3c0a0692761b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd35fb35c4a547629c45f885b38548c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f292ae731c7548af8bcdf0935a682b28",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f75e94cb08f480382cb6c18ecc66ef8",
            "value": 0
          }
        },
        "dcf07be293af4622b8a97d65ab183d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d4e9260aac84b04a4104f93267214be",
            "placeholder": "​",
            "style": "IPY_MODEL_a7d3856191ca486b97e78d7b1a96aa23",
            "value": " 0/3 [00:00&lt;?, ?it/s]"
          }
        },
        "f292ae731c7548af8bcdf0935a682b28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
